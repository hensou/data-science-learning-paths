{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Julia Code\n",
    "\n",
    "Testing plays a crucial role in software development. It helps to ensure that your code works as expected and allows you to make changes to your code with confidence. Julia's standard library includes a Test module for creating and running tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Julia, you can write a test using the @test macro followed by an expression that should evaluate to true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "@test 1 + 1 == 2  # This is a simple test case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Failing Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/cls/Documents/Work/Training/point8/data-science-learning-paths/notebooks/julia/julia-testing.ipynb:1\u001b[22m\n",
      "  Expression: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 == 3\n",
      "   Evaluated: 2 == 3\n",
      "\n"
     ]
    },
    {
     "ename": "Test.FallbackTestSetException",
     "evalue": "Test.FallbackTestSetException(\"There was an error during testing\")",
     "output_type": "error",
     "traceback": [
      "Test.FallbackTestSetException(\"There was an error during testing\")\n",
      "\n",
      "Stacktrace:\n",
      " [1] record(ts::Test.FallbackTestSet, t::Union{Test.Error, Test.Fail})\n",
      "   @ Test /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/Test/src/Test.jl:960\n",
      " [2] do_test(result::Test.ExecutionResult, orig_expr::Any)\n",
      "   @ Test /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/Test/src/Test.jl:670\n",
      " [3] top-level scope\n",
      "   @ /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/Test/src/Test.jl:478"
     ]
    }
   ],
   "source": [
    "@test 1 + 1 == 3  # This is a failing test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Approximate Equality**\n",
    "\n",
    "In most cases, you may want to check that two floating point numbers are approximately equal to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:              | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Approximate equality tests | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Approximate equality tests\", Any[], 1, false, false, true, 1.704664558399567e9, 1.704664558557004e9, false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "@testset \"Approximate equality tests\" begin\n",
    "    @test 0.1 + 0.2 ≈ 0.3 atol=1e-8\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex code, you'll want to organize your tests into \"test sets\". A test set is a group of tests that are related to each other. Test sets can be created using the @testset macro.  If any test within the test set fails, the entire test set is marked as failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Arithmetic tests | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Arithmetic tests\", Any[], 3, false, false, true, 1.704664559245305e9, 1.70466455924536e9, false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "@testset \"Arithmetic tests\" begin\n",
    "    @test 1 + 1 == 2\n",
    "    @test 2 * 2 == 4\n",
    "    @test 2 - 1 == 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametrized Tests**\n",
    "\n",
    "Parameterized tests in Julia allow you to run the same set of tests with different inputs by iterating over a collection of test parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:                            | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Parameterized tests for is_even function | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.0s\n",
      "\u001b[0m\u001b[1mTest Summary:                            | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Parameterized tests for is_even function | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.0s\n",
      "\u001b[0m\u001b[1mTest Summary:                            | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Parameterized tests for is_even function | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.0s\n",
      "\u001b[0m\u001b[1mTest Summary:                            | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Parameterized tests for is_even function | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.0s\n",
      "\u001b[0m\u001b[1mTest Summary:                            | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Parameterized tests for is_even function | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.0s\n",
      "\u001b[0m\u001b[1mTest Summary:                            | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Parameterized tests for is_even function | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6-element Vector{Any}:\n",
       " Test.DefaultTestSet(\"Parameterized tests for is_even function\", Any[], 1, false, false, true, 1.704664909556588e9, 1.704664909565619e9, false)\n",
       " Test.DefaultTestSet(\"Parameterized tests for is_even function\", Any[], 1, false, false, true, 1.704664909568385e9, 1.704664909568393e9, false)\n",
       " Test.DefaultTestSet(\"Parameterized tests for is_even function\", Any[], 1, false, false, true, 1.704664909568641e9, 1.704664909568644e9, false)\n",
       " Test.DefaultTestSet(\"Parameterized tests for is_even function\", Any[], 1, false, false, true, 1.704664909568864e9, 1.704664909568871e9, false)\n",
       " Test.DefaultTestSet(\"Parameterized tests for is_even function\", Any[], 1, false, false, true, 1.70466490956909e9, 1.704664909569096e9, false)\n",
       " Test.DefaultTestSet(\"Parameterized tests for is_even function\", Any[], 1, false, false, true, 1.704664909569321e9, 1.704664909569322e9, false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Function to test\n",
    "function is_even(n)\n",
    "    return n % 2 == 0\n",
    "end\n",
    "\n",
    "# Array of tuples containing test cases\n",
    "# Each tuple has the format (input, expected_output)\n",
    "test_cases = [\n",
    "    (2, true),\n",
    "    (3, false),\n",
    "    (10, true),\n",
    "    (15, false),\n",
    "    (-4, true),\n",
    "    (-7, false)\n",
    "]\n",
    "\n",
    "@testset \"Parameterized tests for is_even function\" for (input, expected) in test_cases\n",
    "    result = is_even(input)\n",
    "    @test result == expected\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test whether a piece of code throws an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Exception test 1 | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Exception test 1\", Any[], 1, false, false, true, 1.704664559266947e9, 1.704664559328487e9, false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "@testset \"Exception test 1\" begin\n",
    "    @test_throws DivideError  1 ÷ 0  # integer division by zero\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception test 2: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/cls/Documents/Work/Training/point8/data-science-learning-paths/notebooks/julia/julia-testing.ipynb:2\u001b[22m\n",
      "  Expression: 1 / 0\n",
      "    Expected: DivideError\n",
      "  No exception thrown\n",
      "\n",
      "Stacktrace:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/Documents/Work/Training/point8/data-science-learning-paths/notebooks/julia/\u001b[39m\u001b[90m\u001b[4mjulia-testing.ipynb:2\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m/opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1498\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/Documents/Work/Training/point8/data-science-learning-paths/notebooks/julia/\u001b[39m\u001b[90m\u001b[4mjulia-testing.ipynb:2\u001b[24m\u001b[39m\n",
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[91m\u001b[1mFail  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Exception test 2 | \u001b[91m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m1.2s\n"
     ]
    },
    {
     "ename": "TestSetException",
     "evalue": "Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.",
     "output_type": "error",
     "traceback": [
      "Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.\n",
      "\n",
      "Stacktrace:\n",
      " [1] finish(ts::Test.DefaultTestSet)\n",
      "   @ Test /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/Test/src/Test.jl:1151\n",
      " [2] macro expansion\n",
      "   @ /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/Test/src/Test.jl:1514 [inlined]\n",
      " [3] top-level scope\n",
      "   @ ~/Documents/Work/Training/point8/data-science-learning-paths/notebooks/julia/julia-testing.ipynb:2"
     ]
    }
   ],
   "source": [
    "@testset \"Exception test 2\" begin\n",
    "    @test_throws DivideError 1 / 0  # floating-point division by zero\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here no exception was thrown since floating point division by zero is possible in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Testing\n",
    "Performance testing is important to ensure that your code runs efficiently. In Julia, you can use the `@time` and `@allocated`` macros to measure how long a piece of code takes to run and how much memory it uses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:       | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Performance testing | \u001b[32m   2  \u001b[39m\u001b[36m    2  \u001b[39m\u001b[0m0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Performance testing\", Any[], 2, false, false, true, 1.704664559595281e9, 1.704664559597832e9, false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "@testset \"Performance testing\" begin\n",
    "    @test @allocated(collect(1:1_000_000)) < 10_000_000  # Check that it allocates less than 10MB\n",
    "    @test @elapsed(sum(1:1_000_000)) < 0.01  # Check that it runs in less than 0.01s\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmarking**\n",
    "\n",
    "- For realistic benchmarking, you typically use the `BenchmarkTools.jl`` package, which provides more comprehensive and statistically sound measurements compared to the @elapsed macro. \n",
    "  - The @elapsed macro simply measures the time it takes to execute a statement once, whereas BenchmarkTools.jl runs the code many times and provides statistical metrics such as the mean, median, minimum, and maximum execution time, as well as the standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BenchmarkTools ─ v1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/Work/Training/point8/data-science-learning-paths/Project.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.4.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/Work/Training/point8/data-science-learning-paths/Manifest.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.4.0\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.1\u001b[39m\n",
      "  \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.0\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.4.1\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.1\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2\u001b[39m\n",
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.9.2\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf\u001b[39m\n",
      "  \u001b[90m[9abbd945] \u001b[39m\u001b[92m+ Profile\u001b[39m\n",
      "  \u001b[90m[3fa0cd96] \u001b[39m\u001b[92m+ REPL\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization\u001b[39m\n",
      "  \u001b[90m[6462fe0b] \u001b[39m\u001b[92m+ Sockets\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.9.0\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.0.5+0\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.4.0+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.0+1\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.2+0\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2022.10.11\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.21+4\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v5.10.1+6\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.13+0\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.8.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.52.0+1\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+0\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
      "  1 dependency successfully precompiled in 2 seconds. 10 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"BenchmarkTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m153.250 μs\u001b[22m\u001b[39m … \u001b[35m220.417 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m153.375 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m154.011 μs\u001b[22m\u001b[39m ± \u001b[32m  2.645 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[32m▄\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  153 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        168 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "# Function to benchmark\n",
    "function sum_inverse_square(n)\n",
    "    return sum(1.0 / (i^2) for i in 1:n)\n",
    "end\n",
    "\n",
    "# Benchmarking with BenchmarkTools\n",
    "benchmark_result = @benchmark sum_inverse_square(100000)\n",
    "\n",
    "# Display the benchmarking result\n",
    "display(benchmark_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2024 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
